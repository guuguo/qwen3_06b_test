# MAC本机本地部署 vs MAC本机Docker部署性能对比

## 系统环境

- **设备**: MacBook Pro M1 Pro (32GB 内存, 8核CPU)
- **模型**: qwen3:0.6b (522MB)
- **测试数据集**: manga_comment_ad_detection (2个样本)
- **测试时间**: 2025-08-06

## 本机本地部署性能数据

### 基线性能 (默认配置)
**来源**: MAC本机 ollama qwen0.6b 吞吐量优化方案.md

| 指标 | 数值 |
|-----|-----|
| **QPS** | **6.53** |
| **吞吐量** | **5.28 tokens/s** |
| 并发用户 | 3 |
| 总请求数 | 221 |
| 成功率 | 100% |
| 平均延迟 | 397.75ms |
| P95延迟 | 668.60ms |
| P99延迟 | 1032.95ms |
| 平均响应长度 | 13.95 tokens |

### 优化后性能 (环境变量优化)
**配置**: OLLAMA_NUM_PARALLEL=4, OLLAMA_MAX_LOADED_MODELS=2, OLLAMA_MAX_QUEUE=10

| 指标 | 优化前 | 优化后 | 提升幅度 |
|-----|--------|--------|---------|
| **QPS** | 6.53 | **7.07** | **+8.3%** ⬆️ |
| **吞吐量** | 5.28 tokens/s | **6.11 tokens/s** | **+15.7%** ⬆️ |
| **平均延迟** | 397.75ms | **332.97ms** | **-16.3%** ⬆️ |
| **P95延迟** | 668.60ms | **370.56ms** | **-44.6%** ⬆️ |
| **P99延迟** | 1032.95ms | **850.48ms** | **-17.6%** ⬆️ |

### 本机配置分析
```bash
# 优化前配置
ollama runner --model qwen3:0.6b \
  --ctx-size 4096 \
  --batch-size 512 \
  --n-gpu-layers 29 \
  --threads 6 \
  --parallel 1

# 优化后环境变量
export OLLAMA_NUM_PARALLEL=4
export OLLAMA_MAX_LOADED_MODELS=2  
export OLLAMA_MAX_QUEUE=10
```

## Docker容器部署性能数据

### 初始配置性能 (严重性能下降)
**Docker配置**: OLLAMA_NUM_THREADS=4, OLLAMA_NUM_PARALLEL=1

| 指标 | 数值 |
|-----|-----|
| 成功率 | 100% (2/2) |
| 评分准确性 | 90.0% |
| 类别准确性 | 0.0% |
| **平均响应时间** | **90725.5ms** |
| **单样本处理时间** | **~45.4秒** |

### 优化后配置性能 (CPU配置调优)
**Docker优化配置**:
```yaml
environment:
  - OLLAMA_NUM_PARALLEL=2      # 允许2个并行请求
  - OLLAMA_MAX_LOADED_MODELS=1
  - OLLAMA_MAX_QUEUE=8         # 增加队列长度
  - OLLAMA_NUM_THREADS=8       # 使用全部CPU核心
  - OLLAMA_KEEP_ALIVE=60s
  - OLLAMA_CONTEXT_LENGTH=4096 # 增加上下文长度
```

**测试状态**: 🔄 当前正在测试中...

## 性能对比分析

### 极端性能差异

| 部署方式 | 平均响应时间 | 性能比值 | 状态 |
|---------|-------------|---------|-----|
| **本机本地** (优化后) | ~333ms | 1x (基准) | ✅ 最优 |
| **本机本地** (默认) | ~398ms | 1.2x | ✅ 良好 |
| **Docker容器** (初始) | ~45,400ms | **136x** | ❌ 极差 |
| **Docker容器** (优化后) | 测试中... | ? | 🔄 优化中 |

### 关键性能瓶颈分析

#### 1. 虚拟化开销
- **Docker层开销**: 容器化导致的系统调用开销
- **资源隔离**: CPU和内存访问的虚拟化损耗
- **预估影响**: 10-20% 性能损失

#### 2. 资源配置差异
| 配置项 | 本机优化 | Docker初始 | Docker优化 |
|-------|---------|-----------|-----------|
| **并行数** | 4 | 1 | 2 |
| **线程数** | 6-8 | 4 | 8 |
| **队列长度** | 10 | 4 | 8 |
| **上下文** | 4096 | 2048 | 4096 |

#### 3. GPU加速差异
| 环境 | GPU层数 | Metal支持 | 性能影响 |
|-----|--------|-----------|---------|
| **本机** | 29层 (几乎全GPU) | 原生Metal | ✅ 最优 |
| **Docker** | 0层? | 无GPU加速? | ❌ 纯CPU |

#### 4. 内存和缓存
- **本机**: 直接访问系统内存，无虚拟化开销
- **Docker**: 内存映射通过容器层，增加延迟

## 问题根因分析

### 主要问题
1. **🚨 Docker GPU加速失效** - 最关键问题
   - Docker环境可能未正确配置GPU加速
   - M1 Pro的Metal GPU未被Docker容器访问
   - 导致回退到纯CPU推理，性能暴跌136倍

2. **🔧 资源配置不当** - 次要问题
   - 线程数配置过低 (4 vs 8)
   - 并行数限制 (1 vs 4)
   - 上下文长度不足 (2048 vs 4096)

3. **🐳 Docker优化不足** - 可优化
   - 容器资源限制设置
   - 内存分配策略
   - 系统调用优化

## 优化建议

### 立即优化 (高优先级)
1. **启用Docker GPU支持**
   ```yaml
   # 需要调研M1 Pro在Docker中的GPU访问方案
   # 可能需要使用 --device 或特殊配置
   ```

2. **对齐资源配置**
   ```yaml
   environment:
     - OLLAMA_NUM_PARALLEL=4        # 匹配本机优化
     - OLLAMA_NUM_THREADS=8         # 使用全部CPU
     - OLLAMA_MAX_QUEUE=10          # 匹配本机配置
   ```

### 中期优化 (中优先级)
1. **容器资源优化**
2. **内存映射优化**
3. **网络延迟优化**

### 预期结果
- **目标性能**: 接近本机性能的80-90%
- **可接受范围**: 延迟增加20-30%
- **当前差距**: 需要缩小136倍的巨大性能差距

---

*文档版本: v1.0*  
*创建时间: 2025-08-06 15:00*  
*状态: 🔄 Docker优化测试进行中*