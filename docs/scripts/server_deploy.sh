#!/bin/bash

# Qwen-3 æœåŠ¡å™¨éƒ¨ç½²è„šæœ¬
# æ”¯æŒ Ubuntu 18.04+ å’Œ CentOS 7+
# ä½¿ç”¨æ–¹æ³•: bash server_deploy.sh [options]

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# é…ç½®å˜é‡
QWEN3_USER="qwen3"
QWEN3_HOME="/opt/qwen3"
QWEN3_LOGS="/var/log/qwen3"
QWEN3_CONFIG="/etc/qwen3"
PYTHON_VERSION="3.9"
OLLAMA_VERSION="latest"

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_step() {
    echo -e "${BLUE}[STEP]${NC} $1"
}

# æ£€æŸ¥æ˜¯å¦ä¸º root ç”¨æˆ·
check_root() {
    if [[ $EUID -ne 0 ]]; then
        log_error "æ­¤è„šæœ¬éœ€è¦ root æƒé™è¿è¡Œ"
        log_info "è¯·ä½¿ç”¨: sudo bash $0"
        exit 1
    fi
}

# æ£€æµ‹æ“ä½œç³»ç»Ÿ
detect_os() {
    if [[ -f /etc/os-release ]]; then
        . /etc/os-release
        OS=$NAME
        VER=$VERSION_ID
    else
        log_error "æ— æ³•æ£€æµ‹æ“ä½œç³»ç»Ÿç‰ˆæœ¬"
        exit 1
    fi
    
    log_info "æ£€æµ‹åˆ°æ“ä½œç³»ç»Ÿ: $OS $VER"
}

# å®‰è£…ç³»ç»Ÿä¾èµ–
install_system_deps() {
    log_step "å®‰è£…ç³»ç»Ÿä¾èµ–..."
    
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        apt-get update
        apt-get install -y \
            curl \
            wget \
            git \
            build-essential \
            software-properties-common \
            apt-transport-https \
            ca-certificates \
            gnupg \
            lsb-release \
            python3 \
            python3-pip \
            python3-venv \
            supervisor \
            nginx \
            htop \
            vim \
            unzip
            
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        yum update -y
        yum groupinstall -y "Development Tools"
        yum install -y \
            curl \
            wget \
            git \
            python3 \
            python3-pip \
            supervisor \
            nginx \
            htop \
            vim \
            unzip
    else
        log_error "ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: $OS"
        exit 1
    fi
    
    log_info "ç³»ç»Ÿä¾èµ–å®‰è£…å®Œæˆ"
}

# åˆ›å»ºç”¨æˆ·å’Œç›®å½•
create_user_and_dirs() {
    log_step "åˆ›å»ºç”¨æˆ·å’Œç›®å½•..."
    
    # åˆ›å»º qwen3 ç”¨æˆ·
    if ! id "$QWEN3_USER" &>/dev/null; then
        useradd -r -m -s /bin/bash "$QWEN3_USER"
        log_info "åˆ›å»ºç”¨æˆ·: $QWEN3_USER"
    else
        log_info "ç”¨æˆ·å·²å­˜åœ¨: $QWEN3_USER"
    fi
    
    # åˆ›å»ºç›®å½•
    mkdir -p "$QWEN3_HOME"/{app,models,logs,config,scripts}
    mkdir -p "$QWEN3_LOGS"
    mkdir -p "$QWEN3_CONFIG"
    
    # è®¾ç½®æƒé™
    chown -R "$QWEN3_USER:$QWEN3_USER" "$QWEN3_HOME"
    chown -R "$QWEN3_USER:$QWEN3_USER" "$QWEN3_LOGS"
    chown -R "$QWEN3_USER:$QWEN3_USER" "$QWEN3_CONFIG"
    
    log_info "ç›®å½•åˆ›å»ºå®Œæˆ"
}

# å®‰è£… Ollama
install_ollama() {
    log_step "å®‰è£… Ollama..."
    
    # ä¸‹è½½å¹¶å®‰è£… Ollama
    curl -fsSL https://ollama.ai/install.sh | sh
    
    # åˆ›å»º systemd æœåŠ¡æ–‡ä»¶
    cat > /etc/systemd/system/ollama.service << 'EOF'
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=qwen3
Group=qwen3
Restart=always
RestartSec=3
Environment="HOME=/opt/qwen3"
Environment="PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

[Install]
WantedBy=multi-user.target
EOF

    # å¯ç”¨å¹¶å¯åŠ¨æœåŠ¡
    systemctl daemon-reload
    systemctl enable ollama
    systemctl start ollama
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    sleep 10
    
    # éªŒè¯æœåŠ¡çŠ¶æ€
    if systemctl is-active --quiet ollama; then
        log_info "Ollama æœåŠ¡å¯åŠ¨æˆåŠŸ"
    else
        log_error "Ollama æœåŠ¡å¯åŠ¨å¤±è´¥"
        systemctl status ollama
        exit 1
    fi
}

# ä¸‹è½½ Qwen-3 æ¨¡åž‹
download_models() {
    log_step "ä¸‹è½½ Qwen-3 æ¨¡åž‹..."
    
    # åˆ‡æ¢åˆ° qwen3 ç”¨æˆ·æ‰§è¡Œ
    sudo -u "$QWEN3_USER" bash << 'EOF'
export HOME=/opt/qwen3
cd $HOME

# ç­‰å¾… Ollama æœåŠ¡å®Œå…¨å¯åŠ¨
sleep 5

# ä¸‹è½½æ¨¡åž‹
echo "ä¸‹è½½ Qwen-3 0.6B æ¨¡åž‹..."
/usr/local/bin/ollama pull qwen3:0.6b

echo "ä¸‹è½½ Qwen-3 1.7B æ¨¡åž‹..."
/usr/local/bin/ollama pull qwen3:1.7b

# éªŒè¯æ¨¡åž‹
echo "éªŒè¯å·²ä¸‹è½½çš„æ¨¡åž‹:"
/usr/local/bin/ollama list
EOF

    log_info "æ¨¡åž‹ä¸‹è½½å®Œæˆ"
}

# å®‰è£… Python åº”ç”¨
install_python_app() {
    log_step "å®‰è£… Python åº”ç”¨..."
    
    # åˆ‡æ¢åˆ° qwen3 ç”¨æˆ·
    sudo -u "$QWEN3_USER" bash << 'EOF'
export HOME=/opt/qwen3
cd $HOME/app

# åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å‡çº§ pip
pip install --upgrade pip

# åˆ›å»º requirements.txt
cat > requirements.txt << 'REQUIREMENTS'
requests>=2.28.0
psutil>=5.9.0
flask>=2.3.0
gunicorn>=20.1.0
transformers>=4.30.0
torch>=2.0.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
tqdm>=4.65.0
pyyaml>=6.0
click>=8.1.0
prometheus-client>=0.16.0
REQUIREMENTS

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

echo "Python çŽ¯å¢ƒå®‰è£…å®Œæˆ"
EOF

    log_info "Python åº”ç”¨å®‰è£…å®Œæˆ"
}

# åˆ›å»ºåº”ç”¨ä»£ç 
create_app_code() {
    log_step "åˆ›å»ºåº”ç”¨ä»£ç ..."
    
    # åˆ›å»ºä¸»åº”ç”¨æ–‡ä»¶
    cat > "$QWEN3_HOME/app/app.py" << 'EOF'
#!/usr/bin/env python3
"""
Qwen-3 æœåŠ¡å™¨åº”ç”¨
"""

import os
import sys
import yaml
import logging
from flask import Flask, request, jsonify
from datetime import datetime
import requests
import time
import psutil
from prometheus_client import Counter, Histogram, Gauge, generate_latest

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/qwen3/app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Prometheus æŒ‡æ ‡
REQUEST_COUNT = Counter('qwen3_requests_total', 'Total requests', ['model', 'status'])
REQUEST_DURATION = Histogram('qwen3_request_duration_seconds', 'Request duration')
ACTIVE_CONNECTIONS = Gauge('qwen3_active_connections', 'Active connections')
SYSTEM_CPU = Gauge('qwen3_system_cpu_percent', 'CPU usage')
SYSTEM_MEMORY = Gauge('qwen3_system_memory_percent', 'Memory usage')

app = Flask(__name__)

class OllamaClient:
    def __init__(self, base_url="http://localhost:11434"):
        self.base_url = base_url
        self.session = requests.Session()
        
    def inference(self, model, prompt, **kwargs):
        """æ¨¡åž‹æŽ¨ç†"""
        start_time = time.time()
        
        try:
            response = self.session.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": model,
                    "prompt": prompt,
                    "stream": False,
                    **kwargs
                },
                timeout=30
            )
            
            duration = time.time() - start_time
            REQUEST_DURATION.observe(duration)
            
            if response.status_code == 200:
                result = response.json()
                REQUEST_COUNT.labels(model=model, status='success').inc()
                return {
                    "status": "success",
                    "response": result.get("response", ""),
                    "model": model,
                    "duration": duration
                }
            else:
                REQUEST_COUNT.labels(model=model, status='error').inc()
                return {
                    "status": "error",
                    "error": f"HTTP {response.status_code}",
                    "duration": duration
                }
                
        except Exception as e:
            duration = time.time() - start_time
            REQUEST_DURATION.observe(duration)
            REQUEST_COUNT.labels(model=model, status='error').inc()
            logger.error(f"æŽ¨ç†é”™è¯¯: {e}")
            return {
                "status": "error",
                "error": str(e),
                "duration": duration
            }

ollama_client = OllamaClient()

@app.route('/health')
def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            return jsonify({"status": "healthy", "timestamp": datetime.now().isoformat()})
        else:
            return jsonify({"status": "unhealthy", "error": "Ollama not responding"}), 503
    except Exception as e:
        return jsonify({"status": "unhealthy", "error": str(e)}), 503

@app.route('/api/v1/inference', methods=['POST'])
def inference():
    """æŽ¨ç†æŽ¥å£"""
    ACTIVE_CONNECTIONS.inc()
    
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Invalid JSON"}), 400
            
        model = data.get('model', 'qwen3:0.6b')
        prompt = data.get('prompt', '')
        
        if not prompt:
            return jsonify({"error": "Prompt is required"}), 400
            
        result = ollama_client.inference(model, prompt, **data.get('options', {}))
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"æŽ¨ç†æŽ¥å£é”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 500
    finally:
        ACTIVE_CONNECTIONS.dec()

@app.route('/api/v1/models')
def list_models():
    """èŽ·å–æ¨¡åž‹åˆ—è¡¨"""
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            data = response.json()
            models = [model['name'] for model in data.get('models', [])]
            return jsonify({"models": models})
        else:
            return jsonify({"error": "Failed to fetch models"}), 500
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/metrics')
def metrics():
    """Prometheus æŒ‡æ ‡"""
    # æ›´æ–°ç³»ç»ŸæŒ‡æ ‡
    SYSTEM_CPU.set(psutil.cpu_percent())
    SYSTEM_MEMORY.set(psutil.virtual_memory().percent)
    
    return generate_latest()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000, debug=False)
EOF

    # è®¾ç½®æƒé™
    chown "$QWEN3_USER:$QWEN3_USER" "$QWEN3_HOME/app/app.py"
    chmod +x "$QWEN3_HOME/app/app.py"
    
    log_info "åº”ç”¨ä»£ç åˆ›å»ºå®Œæˆ"
}

# é…ç½® Supervisor
configure_supervisor() {
    log_step "é…ç½® Supervisor..."
    
    # åˆ›å»º Supervisor é…ç½®
    cat > /etc/supervisor/conf.d/qwen3.conf << 'EOF'
[program:qwen3-api]
command=/opt/qwen3/app/venv/bin/gunicorn --bind 0.0.0.0:8000 --workers 4 --timeout 120 app:app
directory=/opt/qwen3/app
user=qwen3
autostart=true
autorestart=true
stderr_logfile=/var/log/qwen3/api_error.log
stdout_logfile=/var/log/qwen3/api_access.log
environment=HOME="/opt/qwen3",PATH="/opt/qwen3/app/venv/bin:%(ENV_PATH)s"
EOF

    # é‡æ–°åŠ è½½ Supervisor é…ç½®
    supervisorctl reread
    supervisorctl update
    supervisorctl start qwen3-api
    
    log_info "Supervisor é…ç½®å®Œæˆ"
}

# é…ç½® Nginx
configure_nginx() {
    log_step "é…ç½® Nginx..."
    
    # åˆ›å»º Nginx é…ç½®
    cat > /etc/nginx/sites-available/qwen3 << 'EOF'
upstream qwen3_backend {
    server 127.0.0.1:8000;
}

server {
    listen 80;
    server_name _;
    
    client_max_body_size 10M;
    
    location / {
        proxy_pass http://qwen3_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 120s;
    }
    
    location /health {
        proxy_pass http://qwen3_backend/health;
        access_log off;
    }
    
    location /metrics {
        proxy_pass http://qwen3_backend/metrics;
        allow 127.0.0.1;
        deny all;
    }
}
EOF

    # å¯ç”¨ç«™ç‚¹
    ln -sf /etc/nginx/sites-available/qwen3 /etc/nginx/sites-enabled/
    rm -f /etc/nginx/sites-enabled/default
    
    # æµ‹è¯•é…ç½®
    nginx -t
    
    # é‡å¯ Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_info "Nginx é…ç½®å®Œæˆ"
}

# åˆ›å»ºç®¡ç†è„šæœ¬
create_management_scripts() {
    log_step "åˆ›å»ºç®¡ç†è„šæœ¬..."
    
    # åˆ›å»ºçŠ¶æ€æ£€æŸ¥è„šæœ¬
    cat > "$QWEN3_HOME/scripts/status.sh" << 'EOF'
#!/bin/bash

echo "=== Qwen-3 æœåŠ¡çŠ¶æ€ ==="
echo

echo "1. Ollama æœåŠ¡:"
systemctl status ollama --no-pager -l

echo
echo "2. Qwen-3 API æœåŠ¡:"
supervisorctl status qwen3-api

echo
echo "3. Nginx æœåŠ¡:"
systemctl status nginx --no-pager -l

echo
echo "4. ç³»ç»Ÿèµ„æº:"
echo "CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')%"
echo "å†…å­˜: $(free | grep Mem | awk '{printf("%.1f%%", $3/$2 * 100.0)}')"
echo "ç£ç›˜: $(df -h / | awk 'NR==2{printf "%s", $5}')"

echo
echo "5. ç«¯å£ç›‘å¬:"
netstat -tlnp | grep -E ':(80|8000|11434) '

echo
echo "6. å¯ç”¨æ¨¡åž‹:"
curl -s http://localhost:11434/api/tags | python3 -m json.tool 2>/dev/null || echo "æ— æ³•èŽ·å–æ¨¡åž‹åˆ—è¡¨"
EOF

    # åˆ›å»ºé‡å¯è„šæœ¬
    cat > "$QWEN3_HOME/scripts/restart.sh" << 'EOF'
#!/bin/bash

echo "é‡å¯ Qwen-3 æœåŠ¡..."

echo "1. é‡å¯ Ollama..."
systemctl restart ollama
sleep 5

echo "2. é‡å¯ API æœåŠ¡..."
supervisorctl restart qwen3-api
sleep 3

echo "3. é‡å¯ Nginx..."
systemctl restart nginx

echo "4. æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
bash /opt/qwen3/scripts/status.sh
EOF

    # åˆ›å»ºæ—¥å¿—æŸ¥çœ‹è„šæœ¬
    cat > "$QWEN3_HOME/scripts/logs.sh" << 'EOF'
#!/bin/bash

case "$1" in
    "api")
        tail -f /var/log/qwen3/api_access.log
        ;;
    "error")
        tail -f /var/log/qwen3/api_error.log
        ;;
    "ollama")
        journalctl -u ollama -f
        ;;
    "nginx")
        tail -f /var/log/nginx/access.log
        ;;
    *)
        echo "ä½¿ç”¨æ–¹æ³•: $0 {api|error|ollama|nginx}"
        echo "  api    - API è®¿é—®æ—¥å¿—"
        echo "  error  - API é”™è¯¯æ—¥å¿—"
        echo "  ollama - Ollama æœåŠ¡æ—¥å¿—"
        echo "  nginx  - Nginx è®¿é—®æ—¥å¿—"
        ;;
esac
EOF

    # è®¾ç½®æ‰§è¡Œæƒé™
    chmod +x "$QWEN3_HOME/scripts/"*.sh
    chown -R "$QWEN3_USER:$QWEN3_USER" "$QWEN3_HOME/scripts"
    
    log_info "ç®¡ç†è„šæœ¬åˆ›å»ºå®Œæˆ"
}

# éªŒè¯éƒ¨ç½²
verify_deployment() {
    log_step "éªŒè¯éƒ¨ç½²..."
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    sleep 10
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    local services=("ollama" "nginx")
    for service in "${services[@]}"; do
        if systemctl is-active --quiet "$service"; then
            log_info "$service æœåŠ¡è¿è¡Œæ­£å¸¸"
        else
            log_error "$service æœåŠ¡æœªè¿è¡Œ"
            return 1
        fi
    done
    
    # æ£€æŸ¥ API æœåŠ¡
    if supervisorctl status qwen3-api | grep -q "RUNNING"; then
        log_info "API æœåŠ¡è¿è¡Œæ­£å¸¸"
    else
        log_error "API æœåŠ¡æœªè¿è¡Œ"
        return 1
    fi
    
    # æµ‹è¯• API æŽ¥å£
    log_info "æµ‹è¯• API æŽ¥å£..."
    
    local test_result=$(curl -s -X POST http://localhost/api/v1/inference \
        -H "Content-Type: application/json" \
        -d '{"model": "qwen3:0.6b", "prompt": "ä½ å¥½"}' \
        --connect-timeout 10 \
        --max-time 30)
    
    if echo "$test_result" | grep -q "success"; then
        log_info "API æµ‹è¯•æˆåŠŸ"
        echo "$test_result" | python3 -m json.tool
    else
        log_warn "API æµ‹è¯•å¤±è´¥æˆ–è¶…æ—¶"
        echo "å“åº”: $test_result"
    fi
    
    log_info "éƒ¨ç½²éªŒè¯å®Œæˆ"
}

# æ˜¾ç¤ºéƒ¨ç½²ä¿¡æ¯
show_deployment_info() {
    log_step "éƒ¨ç½²ä¿¡æ¯"
    
    echo
    echo "ðŸŽ‰ Qwen-3 æœåŠ¡å™¨éƒ¨ç½²å®Œæˆ!"
    echo
    echo "ðŸ“ æœåŠ¡ä¿¡æ¯:"
    echo "  - API åœ°å€: http://$(hostname -I | awk '{print $1}')/api/v1/inference"
    echo "  - å¥åº·æ£€æŸ¥: http://$(hostname -I | awk '{print $1}')/health"
    echo "  - æŒ‡æ ‡ç›‘æŽ§: http://$(hostname -I | awk '{print $1}')/metrics"
    echo
    echo "ðŸ“‚ é‡è¦è·¯å¾„:"
    echo "  - åº”ç”¨ç›®å½•: $QWEN3_HOME"
    echo "  - æ—¥å¿—ç›®å½•: $QWEN3_LOGS"
    echo "  - é…ç½®ç›®å½•: $QWEN3_CONFIG"
    echo
    echo "ðŸ”§ ç®¡ç†å‘½ä»¤:"
    echo "  - æŸ¥çœ‹çŠ¶æ€: bash $QWEN3_HOME/scripts/status.sh"
    echo "  - é‡å¯æœåŠ¡: bash $QWEN3_HOME/scripts/restart.sh"
    echo "  - æŸ¥çœ‹æ—¥å¿—: bash $QWEN3_HOME/scripts/logs.sh [api|error|ollama|nginx]"
    echo
    echo "ðŸ“‹ æµ‹è¯•å‘½ä»¤:"
    echo "  curl -X POST http://localhost/api/v1/inference \\"
    echo "    -H 'Content-Type: application/json' \\"
    echo "    -d '{\"model\": \"qwen3:0.6b\", \"prompt\": \"ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\"}'"
    echo
}

# ä¸»å‡½æ•°
main() {
    echo "ðŸš€ å¼€å§‹ Qwen-3 æœåŠ¡å™¨éƒ¨ç½²..."
    echo
    
    check_root
    detect_os
    install_system_deps
    create_user_and_dirs
    install_ollama
    download_models
    install_python_app
    create_app_code
    configure_supervisor
    configure_nginx
    create_management_scripts
    verify_deployment
    show_deployment_info
    
    log_info "éƒ¨ç½²å®Œæˆ! ðŸŽ‰"
}

# è§£æžå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        --help|-h)
            echo "Qwen-3 æœåŠ¡å™¨éƒ¨ç½²è„šæœ¬"
            echo
            echo "ä½¿ç”¨æ–¹æ³•: bash $0 [é€‰é¡¹]"
            echo
            echo "é€‰é¡¹:"
            echo "  -h, --help     æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
            echo "  --user USER    æŒ‡å®šè¿è¡Œç”¨æˆ· (é»˜è®¤: qwen3)"
            echo "  --home DIR     æŒ‡å®šå®‰è£…ç›®å½• (é»˜è®¤: /opt/qwen3)"
            echo
            exit 0
            ;;
        --user)
            QWEN3_USER="$2"
            shift 2
            ;;
        --home)
            QWEN3_HOME="$2"
            shift 2
            ;;
        *)
            log_error "æœªçŸ¥é€‰é¡¹: $1"
            exit 1
            ;;
    esac
done

# è¿è¡Œä¸»å‡½æ•°
main
