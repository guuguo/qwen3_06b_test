#!/bin/bash
set -e

echo "ğŸ¤– Configuring Ollama for CPU optimization..."

# ç­‰å¾…OllamaæœåŠ¡å¯åŠ¨
echo "â³ Waiting for Ollama service to start..."
for i in {1..30}; do
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama service is ready!"
        break
    fi
    if [ $i -eq 30 ]; then
        echo "âŒ Ollama service failed to start within 30 seconds"
        exit 1
    fi
    sleep 1
done

# æ£€æŸ¥æ˜¯å¦éœ€è¦é¢„ä¸‹è½½æ¨¡å‹
PRELOAD_MODEL=${PRELOAD_MODEL:-""}
if [ -n "$PRELOAD_MODEL" ]; then
    echo "ğŸ“¥ Pre-downloading model: $PRELOAD_MODEL"
    ollama pull $PRELOAD_MODEL || {
        echo "âš ï¸  Failed to download $PRELOAD_MODEL, continuing without preload"
    }
fi

# æ¨èæœ€ä½³CPUæ¨¡å‹
echo "ğŸ’¡ Recommended CPU-optimized models:"
echo "   - qwen3:0.6b-q4_k_m  (Balanced performance/quality)"
echo "   - qwen3:0.6b-q4_0    (Faster inference)"
echo "   - qwen3:0.6b         (Original model)"

echo "ğŸ¯ Model management available at: http://localhost:5000"
echo "ğŸ”§ To download a model: ollama pull qwen3:0.6b-q4_k_m"

echo "âœ… Ollama configuration completed!"